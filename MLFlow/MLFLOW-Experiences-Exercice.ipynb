{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11ac2e70-7fc0-46e6-a100-9e53166fc160",
   "metadata": {},
   "source": [
    "# MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ecb905-3883-4003-8ebd-4e3418b62478",
   "metadata": {},
   "source": [
    "Pour rappel, la documentation Python de MLFlow se trouve à l'adresse :\n",
    "\n",
    "\n",
    "https://mlflow.org/docs/latest/python_api/index.html\n",
    "\n",
    "Vous allez suivre plusieurs étapes (plusieurs fonctions) qui permettront de lancer des exécutions successives dans la dernière cellule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25022a8f-73cc-4386-bddb-89fae5b0d32d",
   "metadata": {},
   "source": [
    "## Modélisation \n",
    "### Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f9db7f-6abf-4232-a6a1-64b894b4f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1d8199-3a59-47f0-b544-a4fc614afee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96f787a-3c8e-4b7f-9dbb-816fce34975a",
   "metadata": {},
   "source": [
    "### Importation des données : Cancer\n",
    "\n",
    "Récupérez le fichier cancer450.csv et générez en son dataframe.\n",
    "Affiche- le pour vérifier la bonne importation des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad9d191-7ee5-4f97-8acf-2a7cf86f90d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#**A COMPLETER**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c584ee31-9a8b-4ded-a1d0-97cd14c93350",
   "metadata": {},
   "source": [
    "### Split du jeu d'entrainement et de test\n",
    "\n",
    "Séparez le jeu de données en entraînement et test à 80% et une graine de 42.\n",
    "Pour rappel, la variable cible est \"tumor\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac3ecb5-f941-4a61-9ca2-6ba13ded0095",
   "metadata": {},
   "outputs": [],
   "source": [
    "#**A COMPLETER**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a1cd92-52b6-4155-89b9-0495b6393fe6",
   "metadata": {},
   "source": [
    "### Liste des modèles\n",
    "\n",
    "Nous allons travailler avec les modèles suivants : \n",
    "* DecisionTree\n",
    "* LogisticRegression\n",
    "* SVC\n",
    "* GaussianNB\n",
    "* KNeigbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ea02ae-49a7-45e5-a921-4a48ae8f1353",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = ['DT','LR','SVM','NB','KNN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771de46a-22f7-4d4f-933e-b7be94f9a76c",
   "metadata": {},
   "source": [
    "### Hyperparamètres\n",
    "\n",
    "Pour chaque modèle, nous définissons les hyperparamètres dont certains avec de façon aléatoire afin de simuler différentes exécutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610d6d14-055d-4a5d-88ac-1414093a9a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparametre(modele):\n",
    "    if modele == 'DT':\n",
    "        params = {\n",
    "            \"criterion\": 'gini',  # La fonction pour mesurer la qualité d'une scission. Supporté : \"gini\" pour l'impureté de Gini, \"entropy\" pour le gain d'information.\n",
    "            \"splitter\": 'best',  # La stratégie utilisée pour choisir la scission à chaque nœud. Supporté : \"best\" pour choisir la meilleure scission, \"random\" pour choisir la meilleure scission aléatoire.\n",
    "            \"max_depth\": None,  # La profondeur maximale de l'arbre. Si None, alors les nœuds sont étendus jusqu'à ce que toutes les feuilles soient pures ou jusqu'à ce que toutes les feuilles contiennent moins que min_samples_split échantillons.\n",
    "            \"min_samples_split\": random.randint(2, 50),  # Le nombre minimum d'échantillons requis pour scinder un nœud interne.\n",
    "            \"min_samples_leaf\": random.randint(1, 2),  # Le nombre minimum d'échantillons requis pour être à un nœud feuille.\n",
    "            \"min_weight_fraction_leaf\": 0.,  # La fraction pondérée minimale de la somme totale des poids (de tous les échantillons d'entrée) requise pour être à un nœud feuille.\n",
    "            \"max_features\": None,  # Le nombre de fonctionnalités à considérer lors de la recherche de la meilleure scission. Si None, alors max_features=n_features.\n",
    "            \"random_state\": None,  # Contrôle la randomicité de l'estimateur. Les valeurs de l'état aléatoire différentes peuvent changer le comportement de l'arbre.\n",
    "            \"max_leaf_nodes\": None,  # Développe un arbre avec max_leaf_nodes de la meilleure façon. Si None, alors un nombre illimité de nœuds feuilles.\n",
    "            \"min_impurity_decrease\": 0.,  # Un nœud sera scindé si cette scission induit une diminution de l'impureté supérieure ou égale à cette valeur.\n",
    "            \"class_weight\": None,  # Poids associés aux classes. Si None, toutes les classes sont censées avoir un poids un.\n",
    "            \"ccp_alpha\": 0.0,  # Paramètre de complexité utilisé pour la taille minimale de l'arbre de coût-complexité. Plus grande est la valeur de alpha, plus le nombre de nœuds est réduit.\n",
    "        }\n",
    "    elif modele == 'LR':\n",
    "        params = {\n",
    "            \"penalty\": 'l2',  # Spécifie la norme utilisée dans la pénalisation. Les valeurs les plus courantes sont 'l2' et 'l1'.\n",
    "            \"dual\": False,  # Formulation duale ou primale. La formulation duale est seulement implémentée pour la pénalité 'l2' avec des solveurs 'liblinear'. Préférer False dans la majorité des cas.\n",
    "            \"tol\": 1e-4,  # Tolérance pour les critères d'arrêt.\n",
    "            \"C\": 1.0,  # Inverse de la force de régularisation; doit être un flottant positif. Comme dans les machines à vecteurs de support, des valeurs plus petites spécifient une régularisation plus forte.\n",
    "            \"fit_intercept\": True,  # Spécifie si une constante (a.k.a. biais ou intercept) doit être ajoutée à la fonction de décision.\n",
    "            \"intercept_scaling\": random.randint(1, 5),  # Utile seulement lorsque le solveur 'liblinear' est utilisé et 'fit_intercept' est défini à True. Dans ce cas, x devient [x, self.intercept_scaling], c'est-à-dire une colonne \"synthétique\" de poids égaux à intercept_scaling est ajoutée à l'instance vectorielle x.\n",
    "            \"class_weight\": None,  # Poids associés aux classes. Si non spécifié, toutes les classes ont un poids un.\n",
    "            \"random_state\": None,  # Le seed du générateur de nombres pseudo-aléatoires à utiliser lors de la mélange des données.\n",
    "            \"solver\": 'lbfgs',  # Algorithme à utiliser dans le problème d'optimisation. Pour les petits ensembles de données, 'liblinear' est un bon choix, tandis que 'sag' et 'saga' sont plus rapides pour les grands.\n",
    "            \"max_iter\": random.randint(1, 1000),  # Nombre maximal d'itérations prises pour que les solveurs convergent.\n",
    "            \"multi_class\": 'auto',  # Si le choix 'auto', le choix du binaire ou de l'un contre le reste dépend du type de données et du solveur.\n",
    "            \"verbose\": random.randint(1, 10),  # Pour le solveur 'liblinear' et 'lbfgs', définir verbose à tout nombre positif pour la verbosité.\n",
    "            \"warm_start\": False,  # Lorsqu'il est défini à True, réutilise la solution de l'appel précédent pour s'adapter comme initialisation, sinon, efface simplement la solution précédente.\n",
    "            \"n_jobs\": None,  # Nombre de cœurs CPU à utiliser lors de la parallélisation sur des classes. 'None' signifie 1 sauf dans un contexte joblib.parallel_backend. '-1' signifie utiliser tous les processeurs.\n",
    "            \"l1_ratio\": None,  # Le ratio de mélange L1, uniquement utilisé si penalty='elasticnet'. 'l1_ratio=0' correspond à une pénalité L2, 'l1_ratio=1' à une L1. Pour '0 < l1_ratio < 1', la pénalité est une combinaison de L1 et L2.\n",
    "        }\n",
    "    elif modele == 'SVM':\n",
    "        params = {\n",
    "            \"C\": 1.0,  # Paramètre de régularisation. La force de la régularisation est inversement proportionnelle à C. Doit être strictement positif. La pénalité est une norme au carré l2.\n",
    "            \"kernel\": 'rbf',  # Spécifie le type de noyau à utiliser dans l'algorithme. Il doit être 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' ou un appelable.\n",
    "            \"degree\": random.randint(1, 5),  # Degré de la fonction du noyau polynomial ('poly'). Ignoré par tous les autres noyaux.\n",
    "            \"gamma\": 'scale',  # Coefficient du noyau pour 'rbf', 'poly' et 'sigmoid'. Si 'gamma'='scale' (par défaut) est passé alors il utilise 1 / (n_features * X.var()) comme valeur de gamma, si 'auto', utilise 1 / n_features.\n",
    "            \"coef0\": 0.0,  # Terme indépendant dans la fonction du noyau. C'est seulement significatif dans 'poly' et 'sigmoid'.\n",
    "            \"shrinking\": True,  # Utilise la heuristique de shrinking ou non.\n",
    "            \"probability\": False,  # Si vrai, active les estimations de probabilité, ce qui ralentit cette méthode.\n",
    "            \"tol\": 1e-3,  # Tolérance pour le critère d'arrêt.\n",
    "            \"cache_size\": random.randint(1, 1000),  # Taille du cache du noyau (en Mo).\n",
    "            \"class_weight\": None,  # Poids associés aux classes dans le format {classe_label: poids}. Si non spécifié, toutes les classes ont un poids un.\n",
    "            \"verbose\": False,  # Active la sortie verbosité.\n",
    "            \"max_iter\": -1,  # Limite stricte sur les itérations au sein du solveur, ou -1 pour aucune limite.\n",
    "            \"decision_function_shape\": 'ovr',  # Si 'ovr', renvoie la fonction de décision one-vs-rest (n_classes, n_samples) comme toutes les autres classificateurs. Si 'ovo', la fonction de décision one-vs-one (libsvm) est renvoyée (n_classes * (n_classes - 1) / 2, n_samples). Cependant, on peut toujours utiliser `one-vs-rest` en passant 'ovr' à l'option `decision_function_shape` du classificateur `OneVsRestClassifier` explicitement.\n",
    "            \"break_ties\": False,  # Si vrai, la décision de 'decision_function_shape'='ovr', et le nombre de classes > 2, la prédiction brisera les liens selon les valeurs de la fonction de décision. Sinon, le premier parmi les classes liées sera renvoyé.\n",
    "            \"random_state\": None,  # Le seed du générateur de nombres pseudo-aléatoires utilisé lors du mélange des données pour les probabilités d'estimation. Ignoré lorsque 'probability' est False.\n",
    "        }\n",
    "    elif modele == 'NB':\n",
    "        params = {\n",
    "            \"var_smoothing\": 1e-9,  # Portion de la variance la plus grande de toutes les caractéristiques qui est ajoutée à la variance pour la stabilité du calcul.\n",
    "        }\n",
    "    elif modele == 'KNN':\n",
    "        params = {\n",
    "            \"n_neighbors\": random.randint(1, 10),  # nombre de voisins à utiliser\n",
    "            \"weights\": 'uniform',  # poids des points, peut être 'uniform' ou 'distance' ou une fonction personnalisée\n",
    "            \"algorithm\": 'auto',  # algorithme utilisé pour calculer les voisins les plus proches, peut être 'auto', 'ball_tree', 'kd_tree', 'brute'\n",
    "            \"leaf_size\": random.randint(1, 30),  # taille de la feuille passée à BallTree ou KDTree\n",
    "            \"p\": 2,  # paramètre de puissance pour la métrique Minkowski\n",
    "            \"metric\": 'minkowski',  # la métrique de distance à utiliser pour l'arbre\n",
    "            \"metric_params\": None,  # arguments supplémentaires pour la métrique de distance\n",
    "            \"n_jobs\": None,  # nombre de travaux parallèles à exécuter pour la recherche de voisins\n",
    "        }\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de35803-df8d-4e34-9cf9-03644de69ae3",
   "metadata": {},
   "source": [
    "### Entraînement et prédiction du modèle\n",
    "\n",
    "La fonction suivante **entrainement_prediction(n)** est défini comme suit :\n",
    "- ENTREE : name_model qui représente le nom du modèle\n",
    "- SORTIE : retourne le modèle et les prédictions\n",
    "\n",
    "Affecter chaque modèle avec la fonction sklearn qui lui est propre en prenant en compte les hyperparamètres (fonction précédente : hyperparametre(modele))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167c8c8b-3f95-48bd-a055-069cca8e575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrainement_prediction(name_model):\n",
    "    #**A COMPLETER**\n",
    "    return modele, modele.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2598cddc-4581-47f1-919a-afc5c5edac84",
   "metadata": {},
   "source": [
    "### Calculs des metriques\n",
    "\n",
    "Calculez-les métriques suivantes sous forme de fonction :\n",
    "* **accuracy(y_test, y_pred)**\n",
    "* **precision(y_test, y_pred)**\n",
    "* **recall(y_test, y_pred)**\n",
    "* **f1(y_test, y_pred)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a854caa-f12d-460f-b803-bf2d9c7c101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#**A COMPLETER**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6097a995-3978-4ab5-84ff-07ba518ec96b",
   "metadata": {},
   "source": [
    "### Matrice de confusion\n",
    "\n",
    "Cette fonction **conf_matrix(y_test, y_pred)** créé la matrice de confusion, la génère avec matplotlib.pyplot, l'enregistre dans le fichier confusion_matrix.png et retourne le chemin de l'image enregistré sur le disque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb810ad-7e31-4c32-a14c-a159d626d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#**A COMPLETER**\n",
    "def conf_matrix(y_test, y_pred):\n",
    "    # Matrice de confusion\n",
    "\n",
    "    # Génération de la matrice de confusion avec matplotlib\n",
    "    \n",
    "    # Sauvegarde de la figure\n",
    "\n",
    "    return fig_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabe5c9f-3865-46ad-8b07-0f32ee9e39fe",
   "metadata": {},
   "source": [
    "## Trace des expériences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5502e6-f86f-46a3-8262-3add70e64635",
   "metadata": {},
   "source": [
    "Le serveur de suivi (tracking server) est utilisé pour enregistrer et consulter les métriques, les paramètres et les artefacts associés aux différentes exécutions de votre programme de machine learning (expériences). \n",
    "\n",
    "Dans votre environnement et dans une console, démarrez le serveur MLFlow (cherchez dans la documentation) et vérifiez que le serveur est actif en saisissant l'adresse `http://127.0.0.1:5000` dans un navigateur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64c5dd8-f197-48bd-91e8-cf68015f0541",
   "metadata": {},
   "source": [
    "### Définition de l'URI du serveur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aecf50-fb51-4aeb-9573-fd2da3895564",
   "metadata": {},
   "source": [
    "Spécifiez l'URI du tracking server en local sur le port 5000.\n",
    "\n",
    "Vous trouverez l'information dans la documentation Python de MLFlow :\n",
    "https://www.mlflow.org/docs/latest/getting-started/intro-quickstart/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740f6814-8760-4652-b6aa-41cf63b8e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "#**A COMPLETER**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecd4f5b-2d30-4561-a18f-706228e1795d",
   "metadata": {},
   "source": [
    "### Création d'une nouvelle experience\n",
    "\n",
    "L'expérience va vous servir à organiser toutes vos exécutions. \n",
    "\n",
    "Appelez-la \"Experience_cancer\" (set_experiment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43c1a6d-9f38-4671-8efc-09776194e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#**A COMPLETER**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fffc01e-6b56-4ae5-8dd4-f5b79bc36940",
   "metadata": {},
   "source": [
    "### Suivi des exécutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a67c8fa-bb6f-4990-98c2-8f1d1d00570c",
   "metadata": {},
   "source": [
    "Lancez la cellule suivante et observez le résultat sur l'interface MLFlow.\n",
    "\n",
    "Il vous faut compléter au fur et à mesure la cellule tout en relançant l'exécution entre chaque étape ci-dessous pour observer le résultat :\n",
    "\n",
    "1. Récupérez les **prédictions** à partir de la fonction `entrainement_prediction()` et affectez-les à une variable `y_pred`\n",
    "2. Récupérez les **métriques de log** (voir `log_system_metrics` et `time.sleep`)\n",
    "   https://mlflow.org/docs/latest/system-metrics/index.html\n",
    "3. Chargez les **hyperparamètres** avec la fonction `hyperparametre()` (voir `log_param`)\n",
    "4. Ajoutez des **tags** d'information sur le modèle utilisé, par exemple (voir `set_tag`)\n",
    "5. Chargez les **métriques** dans MLFlow (voir `log_metric`)\n",
    "6. Chargez la **matrice de confusion** comme artefact avec la fonction précédente `conf_matrix()` (voir `log_artifact`)\n",
    "7. Chargez les **données** comme artefact (voir `log_artifact`)\n",
    "8. Ajoutez le **dataset** de test dans l'interface des expériences (à l'identique que celui d'entrainement)\n",
    "9. Chargez le **modèle** dans la variable `sk_model` à l'aide de la fonction `entrainement_prediction()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaebcdc-2213-4c07-a5e9-1e671d6346c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    for l in liste:\n",
    "        print(l)\n",
    "        ##########**A COMPLETER**########## 1. Récupération des prédicions\n",
    "\n",
    "        run_description = \"\"\"\n",
    "        Le jeu de données \"Breast Cancer Wisconsin (Diagnostic) Data Set\" est un ensemble de données largement utilisé dans le domaine de l'apprentissage automatique pour la classification binaire, en particulier pour la prédiction du diagnostic de cancer du sein (maligne vs bénigne). \n",
    "        Il a été créé par le Dr. William H. Wolberg à l'Université du Wisconsin-Madison.\n",
    "\n",
    "\n",
    "        L'ensemble de données comprend des caractéristiques calculées à partir d'images numérisées de biopsie de tissus mammaires. \n",
    "        Ces caractéristiques décrivent les noyaux cellulaires présents dans les images et sont calculées à partir d'une image numérisée d'une ponction à l'aiguille fine (FNA) d'une masse mammaire. \n",
    "        Elles incluent des mesures telles que le rayon moyen des cellules, la texture, la périmétrie, l'aire, la douceur, la compacité, la concavité, les points concaves, la symétrie, et la dimension fractale.\n",
    "        \"\"\"\n",
    "    \n",
    "        tags = {\n",
    "            'mlflow.note.content': run_description\n",
    "        }\n",
    "\n",
    "        ##########**A COMPLETER**########## 2. Collecte des metriques de log\n",
    "        with mlflow.start_run(tags=tags) as run:\n",
    "            \n",
    "            # Chargement des métadonnées\n",
    "            mlflow.log_param(\"Nombre de lignes\", X.shape[0])\n",
    "            mlflow.log_param(\"Nombre de caractéristiques\", X.shape[1])\n",
    "            \n",
    "            ##########**A COMPLETER**########## 3. Chargement des Hyperparametres\n",
    "\n",
    "            ##########**A COMPLETER**########## 4. Definition des tags\n",
    "        \n",
    "            ##########**A COMPLETER**########## 5. Chargement des metriques\n",
    "\n",
    "            ##########**A COMPLETER**########## 6. Chargement de la matrice de confusion en temps qu'artefact\n",
    "            \n",
    "            ##########**A COMPLETER**########## 7. Chargement des donnees (Sauvegarde dans un fichie CSV, Enregistrement comme artefact)\n",
    "\n",
    "            dataset_training = mlflow.data.from_pandas(X_train,\n",
    "              source=\"file_path\",\n",
    "              name=\"Cancer\"\n",
    "            )\n",
    "            mlflow.log_input(dataset_training, context=\"training\")\n",
    "\n",
    "            ##########**A COMPLETER**########## 8. Ajout du dataset de test dans l'interface des expériences\n",
    "        \n",
    "            # Signature\n",
    "            #signature = infer_signature(X_train, y_pred)\n",
    "        \n",
    "            #model_info = mlflow.sklearn.log_model(\n",
    "                #sk_model= ##########**A COMPLETER**########## 9. Chargement du modèle\n",
    "                #artifact_path=\"Cancer_Model\",\n",
    "                #signature=signature,\n",
    "                #input_example=X_train,\n",
    "            #)\n",
    "        \n",
    "            eval_data = pd.DataFrame(X_test)\n",
    "            eval_data[\"tumor\"] = y_test.tolist()\n",
    "        \n",
    "        print(mlflow.MlflowClient().get_run(run.info.run_id).data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
